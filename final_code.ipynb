{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fbd864",
   "metadata": {},
   "source": [
    "# Ekstrak Wajah\n",
    "\n",
    "Fungsi ini digunakan untuk mengekstraksi wajah dari sebuah folder gambar (baik struktur flat maupun nested) menggunakan DeepFace. Semua hasil embedding wajah dan metadata akan dikembalikan langsung ke dalam memori (faces_array dan metadata).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff7321",
   "metadata": {},
   "source": [
    "### Argumen:\n",
    "\n",
    "| Parameter           | Tipe  | Deskripsi                                                                                                                         |\n",
    "| ------------------- | ----- | --------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `event_folder_path` | `str` | Path folder yang berisi gambar (bisa berupa direktori gambar langsung atau folder berisi subfolder album).                        |\n",
    "| `min_face_size`     | `int` | Ukuran minimum (dalam piksel) lebar atau tinggi wajah agar dianggap valid. Wajah yang terlalu kecil akan dilewati. Default: `27`. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082ccab",
   "metadata": {},
   "source": [
    "### Return\n",
    "\n",
    "```faces_array```: Numpy array berisi embedding wajah dari seluruh gambar yang valid.\n",
    "\n",
    "```metadata```: List dictionary berisi metadata setiap wajah yang berhasil diekstraksi, termasuk lokasi file asal, area wajah, dan confidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54423e",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "```cropped_dir``` yang berisikan wajah-wajah crop yang sudah dipadding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73376151",
   "metadata": {},
   "source": [
    "### Keterangan Tambahan\n",
    "- Wajah akan dilewati jika:\n",
    "\n",
    "    - Lebar/tingginya terlalu besar (>=800 piksel, kemungkinan gambar penuh).\n",
    "    - Lebar/tingginya lebih kecil dari min_face_size.\n",
    "    - Tidak terdeteksi wajah.\n",
    "    - Wajah dengan confidence < 1\n",
    "- Proses cropping dilakukan dengan padding 30% ke kanan, kiri, atas, dan bawah untuk menjaga kontekstual wajah.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72f6ca",
   "metadata": {},
   "source": [
    "### Struktur Folder yang Didukung\n",
    "\n",
    "**1. Flat Folder**\n",
    "\n",
    "```\n",
    "ef-efekta/\n",
    "├── img1.jpg\n",
    "├── img2.png\n",
    "├── ...\n",
    "```\n",
    "\n",
    "**2. Nested Folder (Album per Subfolder)**\n",
    "```\n",
    "ef-efekta/\n",
    "├── album1/\n",
    "│   ├── a1_img1.jpg\n",
    "│   └── a1_img2.jpg\n",
    "├── album2/\n",
    "│   ├── a2_img1.jpg\n",
    "│   └── a2_img2.jpg\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f9ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "\n",
    "def extract_faces(event_folder_path, min_face_size=27, min_confidence=1.0):\n",
    "    \"\"\"\n",
    "    Extract faces from event folder WITHOUT saving cache, and filter by face confidence.\n",
    "\n",
    "    Args:\n",
    "        event_folder_path (str): Path ke folder gambar (flat atau nested)\n",
    "        min_face_size (int): Ukuran minimal wajah (lebar/tinggi)\n",
    "        min_confidence (float): Confidence minimal agar wajah dianggap valid\n",
    "\n",
    "    Returns:\n",
    "        faces_array (np.ndarray): Embedding wajah yang valid\n",
    "        metadata (List[Dict]): Metadata wajah valid\n",
    "    \"\"\"\n",
    "    if not os.path.exists(event_folder_path):\n",
    "        print(f\"❌ Source folder not found: {event_folder_path}\")\n",
    "        return np.array([]), []\n",
    "\n",
    "    faces, metadata = [], []\n",
    "    event_id = os.path.basename(event_folder_path)\n",
    "\n",
    "    def process_image(img_path, album_id=\"main\", album_name=\"main\"):\n",
    "        nonlocal faces, metadata\n",
    "        try:\n",
    "            result = DeepFace.represent(\n",
    "                img_path=img_path,\n",
    "                model_name=\"Facenet512\",\n",
    "                detector_backend=\"retinaface\",\n",
    "                align=True,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_width, img_height = img.size\n",
    "            img_name = os.path.basename(img_path)\n",
    "\n",
    "            for face_idx, face_data in enumerate(result):\n",
    "                facial_area = face_data['facial_area']\n",
    "                x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "                confidence = face_data.get(\"face_confidence\", 0.0)\n",
    "\n",
    "                if w >= 800 or h >= 800:\n",
    "                    return  # Skip full-image faces\n",
    "                if w < min_face_size or h < min_face_size:\n",
    "                    return  # Skip small faces\n",
    "                if confidence < min_confidence:\n",
    "                    print(f\"⚠️ Skipped face with confidence {confidence:.2f} from {img_path}\")\n",
    "                    return\n",
    "\n",
    "                # Crop with padding\n",
    "                pad = 0.3\n",
    "                new_x = max(0, x - int(w * pad))\n",
    "                new_y = max(0, y - int(h * pad))\n",
    "                new_w = min(img_width, x + w + int(w * pad)) - new_x\n",
    "                new_h = min(img_height, y + h + int(h * pad)) - new_y\n",
    "                cropped_img = img.crop((new_x, new_y, new_x + new_w, new_y + new_h))\n",
    "                cropped_name = f\"{os.path.splitext(img_name)[0]}_f-{face_idx}.jpg\"\n",
    "                cropped_path = os.path.join(\"cropped_dir\", cropped_name)\n",
    "                os.makedirs(\"cropped_dir\", exist_ok=True)\n",
    "                cropped_img.save(cropped_path)\n",
    "\n",
    "                face_vector = face_data['embedding']\n",
    "                faces.append(face_vector)\n",
    "                metadata.append({\n",
    "                    \"foto_id\": f\"{os.path.basename(img_path)}_f-{face_idx}\",\n",
    "                    \"album\": {\n",
    "                        \"id\": album_id,\n",
    "                        \"name\": album_name,\n",
    "                        \"event\": {\n",
    "                            \"id\": event_id,\n",
    "                            \"name\": event_id\n",
    "                        }\n",
    "                    },\n",
    "                    \"embedding\": face_vector,\n",
    "                    \"cluster_id\": None,\n",
    "                    \"path\": img_path,\n",
    "                    \"facial_area\": facial_area,\n",
    "                    \"face_confidence\": confidence\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {img_path}: {e}\")\n",
    "\n",
    "    # Check folder structure\n",
    "    items = os.listdir(event_folder_path)\n",
    "    image_files = [f for f in items if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "    subdirs = [f for f in items if os.path.isdir(os.path.join(event_folder_path, f))]\n",
    "\n",
    "    if image_files:\n",
    "        print(\"📁 Flat folder mode\")\n",
    "        with tqdm(total=len(image_files), desc=\"Processing Images\") as pbar:\n",
    "            for fname in image_files:\n",
    "                process_image(os.path.join(event_folder_path, fname))\n",
    "                pbar.update(1)\n",
    "\n",
    "    elif subdirs:\n",
    "        print(\"📁 Nested folder mode\")\n",
    "        total = sum(len(os.listdir(os.path.join(event_folder_path, sd))) for sd in subdirs)\n",
    "        with tqdm(total=total, desc=\"Processing Albums\") as pbar:\n",
    "            for album_name in subdirs:\n",
    "                album_path = os.path.join(event_folder_path, album_name)\n",
    "                for fname in os.listdir(album_path):\n",
    "                    if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                        process_image(os.path.join(album_path, fname), album_id=album_name, album_name=album_name)\n",
    "                    pbar.update(1)\n",
    "    else:\n",
    "        print(\"❌ No images or subdirectories found.\")\n",
    "        return np.array([]), []\n",
    "\n",
    "    faces_array = np.array(faces)\n",
    "    print(f\"\\n✅ Done! Total valid faces: {len(faces_array)}, Metadata: {len(metadata)}\")\n",
    "    return faces_array, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FOLDER = \"ef-efekta\"  #---nama folder\n",
    "faces, metadata = extract_faces(SOURCE_FOLDER)\n",
    "\n",
    "print(f\"Jumlah wajah ditemukan: {len(faces)}\")\n",
    "print(f\"Dimensi embedding: {faces.shape[1] if len(faces) > 0 else 'N/A'}D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff210bb8",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31478a88",
   "metadata": {},
   "source": [
    "Fungsi ini melakukan clustering embedding wajah menggunakan gabungan UMAP (untuk reduksi dimensi) dan HDBSCAN (untuk clustering), lalu secara otomatis mengorganisasi wajah ke dalam folder sesuai hasil cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2af1e",
   "metadata": {},
   "source": [
    "### Argumen \n",
    "\n",
    "| Parameter          | Tipe         | Deskripsi                                                                        |\n",
    "| ------------------ | ------------ | -------------------------------------------------------------------------------- |\n",
    "| `faces`            | `np.ndarray` | Array berisi embedding wajah berdimensi tinggi (contoh: `(N, 512)`)              |\n",
    "| `metadata`         | `List[dict]` | Daftar metadata tiap wajah (harus sejajar dengan `faces`)                        |\n",
    "| `min_cluster_size` | `int`        | Ukuran minimal satu cluster. Wajah lebih sedikit dari nilai ini dianggap outlier |\n",
    "| `metric`           | `str`        | Metode pengukuran jarak untuk HDBSCAN (`'euclidean'`, `'manhattan'`, dll)        |\n",
    "| `output_dir`       | `str`        | Nama folder output untuk menyimpan hasil clustering wajah                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff13481",
   "metadata": {},
   "source": [
    "### Return \n",
    "\n",
    "```cluster_labels``` → ```np.ndarray``` berisi label cluster untuk setiap wajah (-1 berarti outlier)\n",
    "\n",
    "```n_clusters``` → jumlah cluster valid (tidak termasuk outlier)\n",
    "\n",
    "```n_outliers``` → jumlah wajah yang tidak masuk ke cluster manapun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4ffa3",
   "metadata": {},
   "source": [
    "### Konfigurasi\n",
    " \n",
    "**UMAP**\n",
    "- n_neighbors: 3\n",
    "- n_components: 38 (untuk jumlah wajah diatas 1000 wajah --> n_components: 35) \n",
    "- min_dist: 0.0\n",
    "- metric: cosine\n",
    "- random_state: 42\n",
    "\n",
    "**Dinamika n_components UMAP**\n",
    "\n",
    "- Jika jumlah wajah > 1000 → n_components = 35\n",
    "- Jika jumlah wajah ≤ 1000 → n_components = 38\n",
    "\n",
    "**HDBSCAN**\n",
    "- Min clusster size: 2\n",
    "-  Metric: euclidean\n",
    "- min_samples: 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c8422",
   "metadata": {},
   "source": [
    "### Struktur output \n",
    "\n",
    "```\n",
    "clustered_faces/\n",
    "├── cluster_00/\n",
    "│   ├── IMG001_f0.jpg\n",
    "│   ├── IMG010_f1.jpg\n",
    "│   └── ...\n",
    "├── cluster_01/\n",
    "│   └── ...\n",
    "└── outliers/\n",
    "    └── IMG099_f3.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445896a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "def cluster_faces(faces, metadata, min_cluster_size=2, metric='euclidean', output_dir=\"clustered_faces\"):\n",
    "    \"\"\"\n",
    "    Cluster face embeddings using UMAP + HDBSCAN and organize into folders.\n",
    "\n",
    "    Args:\n",
    "        faces (np.ndarray): Embedding vectors for each face (e.g., shape (N, 512))\n",
    "        metadata (list[dict]): Metadata list, one per face\n",
    "        min_cluster_size (int): Minimum number of samples in a cluster\n",
    "        metric (str): Distance metric for clustering (e.g., 'euclidean', 'manhattan')\n",
    "        output_dir (str): Output directory to save clustered faces\n",
    "\n",
    "    Returns:\n",
    "        tuple: (cluster_labels, n_clusters, n_outliers)\n",
    "    \"\"\"\n",
    "    n_faces = len(faces)\n",
    "    if n_faces == 0:\n",
    "        print(\"❌ No face embeddings provided.\")\n",
    "        return np.array([]), 0, 0\n",
    "\n",
    "    if n_faces < min_cluster_size:\n",
    "        print(f\"⚠️ Only {len(faces)} faces available; min_cluster_size={min_cluster_size}\")\n",
    "        cluster_labels = np.array([-1] * len(faces))\n",
    "        _organize_faces(metadata, cluster_labels, output_dir)\n",
    "        return cluster_labels, 0, len(faces)\n",
    "    \n",
    "    n_components = 35 if n_faces > 1000 else 38\n",
    "    # UMAP Dimensionality Reduction\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=3,\n",
    "        n_components=n_components,\n",
    "        min_dist=0.0,\n",
    "        metric='cosine',\n",
    "        random_state=42\n",
    "    )\n",
    "    reduced_embeddings = reducer.fit_transform(faces)\n",
    "\n",
    "    # HDBSCAN Clustering\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=2,\n",
    "        metric=metric,\n",
    "        cluster_selection_method='eom'\n",
    "    )\n",
    "    cluster_labels = clusterer.fit_predict(reduced_embeddings)\n",
    "\n",
    "    n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    n_outliers = list(cluster_labels).count(-1)\n",
    "\n",
    "    # Update metadata with cluster_id\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        metadata[i]['cluster_id'] = int(label)\n",
    "\n",
    "    # Organize clustered faces into folders\n",
    "    _organize_faces(metadata, cluster_labels, output_dir)\n",
    "\n",
    "    print(f\"✅ Clustering completed: {n_clusters} clusters, {n_outliers} outliers.\")\n",
    "    return cluster_labels, n_clusters, n_outliers\n",
    "\n",
    "\n",
    "def _organize_faces(metadata, cluster_labels, output_dir):\n",
    "    \"\"\"\n",
    "    Copy face images into folders based on their cluster labels.\n",
    "    \"\"\"\n",
    "    print(\"📁 Organizing faces into cluster folders...\")\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "    cluster_groups = defaultdict(list)\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        cluster_groups[label].append(metadata[i])\n",
    "\n",
    "    for cluster_id, faces_in_cluster in cluster_groups.items():\n",
    "        folder_name = \"outliers\" if cluster_id == -1 else f\"cluster_{cluster_id:02d}\"\n",
    "        cluster_dir = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "        for face_data in faces_in_cluster:\n",
    "            src_path = face_data['foto_id']\n",
    "            if os.path.exists(src_path):\n",
    "                dst_path = os.path.join(cluster_dir, os.path.basename(src_path))\n",
    "                shutil.copy2(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels, n_clusters, n_outliers = cluster_faces(\n",
    "    faces=faces,\n",
    "    metadata=metadata,\n",
    "    output_dir=\"clustered_faces\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491ef67",
   "metadata": {},
   "source": [
    "# Pengambilan Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4a889",
   "metadata": {},
   "source": [
    "Fungsi ini menghitung centroid (rata-rata embedding) dan memilih satu wajah yang paling representatif (paling mirip centroid) dari setiap cluster.\n",
    "\n",
    "### Parameter:\n",
    "- `metadata` (`list`): List metadata wajah, wajib memiliki `embedding` dan `cluster_id`.\n",
    "\n",
    "### Output:\n",
    "Dictionary per `cluster_id` dengan struktur:\n",
    "- `centroid_embedding`: Vektor centroid (vektor dari wajah yang paling mendekati mean).\n",
    "- `representative`: Metadata wajah paling mirip centroid.\n",
    "- `centroid_id`: Path file dari wajah representatif.\n",
    "- `event_id`, `album_id`: ID event dan album berdasarkan nama file.\n",
    "- `members`: Seluruh anggota cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac772cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_centroids(metadata: list) -> dict:\n",
    "    \"\"\"\n",
    "    Menghitung centroid (rata-rata embedding) dan metadata representatif dari tiap cluster wajah.\n",
    "\n",
    "    Parameters:\n",
    "        metadata (list): Daftar metadata dari wajah yang memiliki 'cluster_id' dan 'embedding'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary berisi centroid embedding, metadata representatif, dan anggota cluster untuk setiap cluster_id.\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_to_items = defaultdict(list)\n",
    "    for item in metadata:\n",
    "        cluster_id = item.get(\"cluster_id\")\n",
    "        if cluster_id == -1 or item.get(\"embedding\") is None:\n",
    "            continue\n",
    "        cluster_to_items[cluster_id].append(item)\n",
    "\n",
    "    centroids = {}\n",
    "\n",
    "    for cluster_id, items in cluster_to_items.items():\n",
    "        embeddings = np.array([item[\"embedding\"] for item in items])\n",
    "\n",
    "        # Hitung centroid sebagai rata-rata\n",
    "        centroid_vec = np.mean(embeddings, axis=0)\n",
    "\n",
    "        # Cari wajah paling mirip dengan centroid\n",
    "        sims = cosine_similarity([centroid_vec], embeddings)[0]\n",
    "        best_idx = np.argmax(sims)\n",
    "        representative_meta = items[best_idx]\n",
    "\n",
    "        # Ekstrak event_id dan album_id dari nama file\n",
    "        filename = os.path.basename(representative_meta[\"foto_id\"])\n",
    "        name_wo_ext = os.path.splitext(filename)[0]\n",
    "        album_id = name_wo_ext.split(\"_\")[0]\n",
    "        event_id = ''.join(filter(str.isalpha, album_id))\n",
    "\n",
    "        # Simpan hasil ke dict\n",
    "        centroids[cluster_id] = {\n",
    "            \"cluster_id\": str(cluster_id),\n",
    "            \"event_id\": representative_meta['album']['event']['name'],\n",
    "            \"album_id\": representative_meta['album']['name'],\n",
    "            \"centroid_id\": representative_meta[\"foto_id\"],\n",
    "            \"centroid_embedding\": representative_meta['embedding'],\n",
    "            \"representative\": representative_meta,\n",
    "            \"members\": items,\n",
    "        }\n",
    "\n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbe5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = compute_centroids(metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f552e7",
   "metadata": {},
   "source": [
    "# ChromaDB untuk Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd0cb7c",
   "metadata": {},
   "source": [
    "\n",
    "Embedding wajah disimpan ke koleksi `face_embeddings` pada ChromaDB menggunakan metode pencocokan `cosine`. Metadata setiap wajah disimpan dalam format string agar bisa dicari kembali.\n",
    "\n",
    "### Struktur Metadata:\n",
    "- `foto_id`: Path ke file wajah ter-crop\n",
    "- `album_id`: ID album\n",
    "- `event_id`: ID event\n",
    "- `cluster_id`: ID cluster hasil clustering\n",
    "- `path`: Path ke original image\n",
    "- `face_confidence`: Confidence deteksi wajah\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Inisialisasi ChromaDB client dan collection\n",
    "client = chromadb.PersistentClient(path=\"chroma\")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"face_embeddings\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}  # pastikan pakai 'cosine'\n",
    ")\n",
    "\n",
    "print(\"\\n💾 Menyimpan data ke ChromaDB...\")\n",
    "\n",
    "# Menyimpan setiap embedding ke ChromaDB\n",
    "for idx, (face_vector, meta) in enumerate(zip(faces, metadata)):\n",
    "    doc_id = f\"face-{idx}\"\n",
    "\n",
    "    # Metadata harus bertipe string\n",
    "    str_metadata = {\n",
    "        \"foto_id\": meta.get(\"foto_id\", \"\"),\n",
    "        \"album_id\": meta.get(\"album\", {}).get(\"id\", \"\"),\n",
    "        \"event_id\": meta.get(\"album\", {}).get(\"event\", {}).get(\"id\", \"\"),\n",
    "        \"cluster_id\": str(meta.get(\"cluster_id\", \"\")),\n",
    "        \"path\": meta.get(\"path\", \"\"),\n",
    "        \"face_confidence\": str(meta.get(\"face_confidence\", \"\"))\n",
    "    }\n",
    "\n",
    "    collection.add(\n",
    "        ids=[doc_id],\n",
    "        embeddings=[face_vector],\n",
    "        metadatas=[str_metadata],\n",
    "        documents=[meta[\"foto_id\"]]\n",
    "    )\n",
    "\n",
    "print(f\"✅ {len(faces)} embeddings berhasil disimpan ke ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d47ca",
   "metadata": {},
   "source": [
    "### 🔍 search_similar_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ed416",
   "metadata": {},
   "source": [
    "Fungsi ini digunakan untuk melakukan pencarian `top_k` wajah yang paling mirip dengan embedding yang diberikan. Dihitung menggunakan cosine similarity melalui ChromaDB.\n",
    "\n",
    "### Parameter:\n",
    "- `query_vector`: Vektor embedding yang ingin dicari kemiripannya.\n",
    "- `collection_name`: Nama koleksi dalam ChromaDB (default: `\"face_embeddings\"`).\n",
    "- `top_k`: Jumlah wajah paling mirip yang ditampilkan.\n",
    "\n",
    "### Contoh Penggunaan:\n",
    "```python\n",
    "results = search_similar_faces(query_vector=your_embedding, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64851e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_faces(query_vector, collection_name=\"face_embeddings\", top_k=10):\n",
    "    \"\"\"\n",
    "    Melakukan pencarian wajah paling mirip dari database ChromaDB berdasarkan vektor embedding.\n",
    "\n",
    "    Args:\n",
    "        query_vector (list/np.array): Vektor embedding query wajah.\n",
    "        collection_name (str): Nama koleksi di ChromaDB.\n",
    "        top_k (int): Jumlah hasil wajah mirip yang ingin ditampilkan.\n",
    "\n",
    "    Returns:\n",
    "        dict: Hasil pencarian dari ChromaDB.\n",
    "    \"\"\"\n",
    "    import chromadb\n",
    "\n",
    "    # Connect ke database lokal\n",
    "    client = chromadb.PersistentClient(path=\"chroma\")\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "\n",
    "    # Query ke ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_vector,\n",
    "        n_results=top_k,\n",
    "        include=[\"distances\", \"metadatas\"]\n",
    "    )\n",
    "\n",
    "    # Tampilkan hasil pencarian\n",
    "    print(f\"\\n🔍 Found {len(results['ids'][0])} similar faces:\")\n",
    "    for i, (doc_id, metadata, distance) in enumerate(zip(\n",
    "        results['ids'][0],\n",
    "        results['metadatas'][0],\n",
    "        results['distances'][0]\n",
    "    )):\n",
    "        print(f\"{i+1}. ID: {doc_id}\")\n",
    "        print(f\"   ➤ Foto ID: {metadata.get('foto_id')}\")\n",
    "        print(f\"   ➤ Path: {metadata.get('path')}\")\n",
    "        print(f\"   ➤ Distance: {distance:.4f}\")\n",
    "        print(\"---\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853b942",
   "metadata": {},
   "source": [
    "# ChromaDB untuk Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f910e6",
   "metadata": {},
   "source": [
    "Menyimpan data centroid dari hasil clustering wajah ke dalam ChromaDB dengan struktur metadata yang mencakup event_id, album_id, cluster_id, dan lainnya.\n",
    "\n",
    "### Parameter\n",
    "```centroids``` (```dict```): Dictionary hasil clustering yang memuat informasi embedding, foto_id, dan metadata representatif lainnya.\n",
    "\n",
    "```collection_name``` (str, default \"centroids_collection\"): Nama koleksi yang akan digunakan di ChromaDB.\n",
    "\n",
    "### Output\n",
    "Menampilkan log jumlah centroid yang berhasil disimpan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def save_centroids_to_chromadb(centroids, collection_name=\"centroids_collection\"):\n",
    "    # Inisialisasi Chroma client\n",
    "    client = chromadb.PersistentClient(path=\"cluster\")\n",
    "\n",
    "    # Buat atau dapatkan koleksi\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # disarankan tetap pakai cosine\n",
    "    )\n",
    "\n",
    "    ids = []\n",
    "    embeddings = []\n",
    "    metadatas = []\n",
    "\n",
    "    for cluster_id, data in centroids.items():\n",
    "        representative_meta = data[\"representative\"]\n",
    "        foto_id = representative_meta[\"foto_id\"]\n",
    "\n",
    "        album_id = representative_meta[\"album\"]['event']['name']\n",
    "        event_id = representative_meta[\"album\"]['name']\n",
    "\n",
    "        centroid_id = f\"{event_id}_{cluster_id}\"  # format unik ID\n",
    "\n",
    "        ids.append(centroid_id)\n",
    "        embeddings.append(data[\"centroid_embedding\"])  # <- hasil centroid vec as list\n",
    "        metadatas.append({\n",
    "            \"cluster_id\": str(cluster_id),\n",
    "            \"event_id\": event_id,\n",
    "            \"album_id\": album_id,\n",
    "            \"centroid_id\": centroid_id,\n",
    "            \"foto_id\": foto_id\n",
    "        })\n",
    "\n",
    "    # Simpan ke Chroma\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Saved {len(ids)} centroids to collection '{collection_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ae732",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_centroids_to_chromadb(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cbe386",
   "metadata": {},
   "source": [
    "### 🔍 search_similar_centroids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20da9c5",
   "metadata": {},
   "source": [
    "Fungsi ini melakukan pencarian centroid yang paling mirip dengan vektor wajah yang diberikan menggunakan **cosine similarity** di koleksi ChromaDB.\n",
    "\n",
    "### Parameter\n",
    "- `query_embedding` (`list[float]`): Vektor embedding wajah yang ingin dicocokkan.\n",
    "- `top_k` (`int`, optional): Jumlah hasil terdekat yang ditampilkan. Default: `5`.\n",
    "- `collection_name` (`str`, optional): Nama koleksi tempat pencarian. Default: `\"centroids_collection\"`.\n",
    "\n",
    "### Proses\n",
    "1. Hubungkan ke koleksi ChromaDB menggunakan `PersistentClient`.\n",
    "2. Lakukan pencarian terhadap `query_embedding`.\n",
    "3. Tampilkan hasil pencarian dengan metadata dan jarak cosine-nya.\n",
    "\n",
    "### Output\n",
    "Menampilkan daftar hasil terdekat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fde7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_centroids(query_embedding, top_k=5, collection_name=\"centroids_collection\"):\n",
    "    import chromadb\n",
    "    client = chromadb.PersistentClient(path=\"cluster\")\n",
    "\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    # Search berdasarkan embedding centroid (cosine distance default)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        print(f\"{i+1}. Centroid ID: {results['ids'][0][i]}\")\n",
    "        print(f\"   ➤ Face ID: {results['metadatas'][0][i]['foto_id']}\")\n",
    "\n",
    "        print(f\"   ➤ Event ID: {results['metadatas'][0][i]['event_id']}\")\n",
    "        print(f\"   ➤ Album ID: {results['metadatas'][0][i]['album_id']}\")\n",
    "        print(f\"   ➤ Cluster ID: {results['metadatas'][0][i]['cluster_id']}\")\n",
    "        print(f\"   ➤ Distance (cosine): {results['distances'][0][i]:.4f}\")\n",
    "        print(\"---\")\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
